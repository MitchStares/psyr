---
title: "Chapter 7. Other Applications"
output:
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    highlight: textmate
    css: mystyle.css
    number_sections: true
    pandoc_args: [
      "--number-offset", 7
    ]
---

```{r,echo=FALSE}
rm(list=objects()) # start with a clean workspace
source("knitr_tweaks.R")
library(shiny, quietly = TRUE)
library(shinyjs, quietly = TRUE)
library(rdrop2, quietly = TRUE)
```

## Twitter client

Researchers interested in social networks often scrape data from sites such as Twitter in order to obtain data. This is relatively easy to do in R, using a package like `twitteR`, which provides an interface with the Twitter web API. 

### Setting up `twitteR`

It's fairly easy to get set up (e.g. [this post](https://www.r-bloggers.com/setting-up-the-twitter-r-package-for-text-analytics/)): 

1. Install the `twitteR` package
2. Get a twitter account 
     - I have @lsrbook for this
     - you do need to add a mobile number (for Australian numbers, drop the leading 0)
3. Go to https://apps.twitter.com (sign in with your account)
4. Click on "create new app"
5. Enter the information it requests: you need a name, a description, a website. For my client I set
     - lsr-book-twitter-app
     - R twitter client for teaching purposes
     - I used https://learningstatisticswithr.com (the post suggests: https://bigcomputing.blogspot.com)
6. Agree to terms and conditions

At this point the app is created on the Twitter side. You'll need to get some information to allow R access to the app:

7. Click on "key & access token" tab and get the following:
      - Consumer Key (API Key)
      - Consumer Secret (API Secret)
8. Go to the "create my access token" button:
      - Access Token
      - Access Token Secret

This is all R needs so go back to R and enter the following:

```{r,eval=FALSE}
consumer_key <- "XXXXX"
consumer_secret <- "XXXXX"
access_token <- "XXXXX"
access_secret <- "XXXXX"
```

where the `"XXXXX"` values are of course the keys you just downloaded. Within R the command to authorise the `twitteR` package access to the app is:

```
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
```
Now we're ready to go!

### Using the Twitter client

Okay, so I guess people like to tweet about `#thedrum` so I decided to search for the last 10000 tweets containing that term. It's easy to do:

```{r, eval=FALSE}
library(twitteR)

drumtweet10k <- searchTwitter(
  searchString = "thedrum", 
  n=10000
)
```

```{r,echo=FALSE,eval=FALSE}
load("dt10k.Rdata")

dt10k_txt <- sapply(drumtweet10k, function(x){x$text})
dt10k_bow <- unlist(strsplit(dt10k_txt, " "))

dt10k_stp <- dt10k_bow
dt10k_stp <- gsub("&amp;","&",dt10k_stp,fixed=TRUE)
stopchars <- strsplit("[\\:!$%&()*+,-./;<=>'[]^_]","")[[1]]
for(s in stopchars) {
  dt10k_stp <- gsub(s,"",dt10k_stp,fixed=TRUE)
}
dt10k_stp <- gsub(" ","",dt10k_stp,fixed=TRUE)
dt10k_stp <- iconv(dt10k_stp, "latin1", "ASCII", sub="")
dt10k_stp <- tolower(dt10k_stp)

stopwords <- as.character(unlist(read.csv("./stop-word-list.csv",header=FALSE)))
stopwords <- gsub(" ","",stopwords,fixed=TRUE)
stopwords <- c(stopwords," ")

boring <- dt10k_stp %in% stopwords
dt10k_stp <- dt10k_stp[!boring]
dt10k_stp <- dt10k_stp[nchar(dt10k_stp)>0]

freq <- table(dt10k_stp)
freq <- sort(freq,decreasing = TRUE)[1:100]

save(freq,dt10k_stp,dt10k_txt,stopchars,stopwords,file="./data/dt10k-sml.Rdata")
```

The raw data are saved in the `dt10k.Rdata`. The format of the data is a little complicated, so I did a tiny bit of text processing and tidying, and then saved the results to `dt10k-sml.Rdata`. Let's take a look:

```{r}
load("./data/dt10k-sml.Rdata")
library(lsr)
who()
```

In the full data set the twitter client has downloaded a lot of information about each tweet, but in this simpler versionm `dt10k_txt` variable contains only the raw text of each tweet. Here's the first few tweets:
```{r}
dt10k_txt[1:5]
```

The `dt10k_stp` vector concatenates all the tweets, splits them so that each word is a separate element, after removing punctuation characters, converting everthing to lower case, and removing certain `stopwords` that are very high frequency but rarely interesting:

```{r}
dt10k_stp[1:50]
```

The `freq` variable is a frequency table for the words in `dt10k_stp`, sorted in order of decreasing frequency. Here are the top 20 words:

```{r}
names(freq[1:20])
```

Just to illustrate that there is psychological value in this approach, here's the standard "rank-frequency plot", showing the signature (approximately) power-law behaviour. There are a few *extremely* common words, and then a *very* long tail of low frequency words. Variations on this pattern are ubiquitous in natural language:  

```{r,fig.width=7}
plot(
  x = freq[1:100], 
  xlab="Word", 
  ylab="Frequency"
)
```

That said, I do wonder how much of this data set is spam. There seem to be a lot of tweets about blockchain in there, which does make me suspicious. I may have to revisit this example in the future!


## Animated plots

- You need [ffmpeg](http://ffmpeg.org/) installed first (this can be tedious)
- The `animate` package does the work in R: an animation is just a sequence of plots that can be written to a variety of different animation formats 
- Example:

```{r,fig.show="animate", interval=0.1, aniopts="controls", fig.width=5, fig.height=5,cache=TRUE,echo=FALSE}

n <- 100           # number of points
col <- rainbow(n)  # all the colours of the rainbow
s <- .02           # how much noise in the diffusion
ntime <- 200       # how many time points

# drift
phi <- seq(0,pi,length.out = n) # angle of the drift
nu <- .015                      # rate of the drift
dx <- nu * cos(phi)  # x-component of drift
dy <- nu * sin(phi)  # y-component of drift

# start
x <- y <- rep.int(0,n)    # all points at the origin
moving <- rep.int(TRUE,n) # all points moving

# storage
points <- list()
points[[1]] <- list(x=x,y=y)

# iterate over time
for(i in 2:ntime){
  nm <- sum(moving) # how many points are moving 
  
  x[moving] <- x[moving] + dx[moving] + rnorm(nm)*s # move x co-ord
  y[moving] <- y[moving] + dy[moving] + rnorm(nm)*s # move y co-ord
  
  l <- x^2 + y^2            # have we hit boundary
  moving[l >= 1] <- FALSE   # freeze points when we do
  
  points[[i]] <- list(x=x,y=y) # storage
}

op <- par(no.readonly = TRUE) # plot set up
par(mar=c(1,1,1,1))           # plot margins
th <- seq(0,2*pi,.01)         # points for outer circle

for(i in seq(ntime,1,-1)) { # go backwards in time to be pretty!
  
  # initialise plot
  plot.new()
  plot.window(
    xlim=c(-1.1,1.1),
    ylim=c(-1.1,1.1)
  )
  
  # read the current locations
  x <- points[[i]]$x
  y <- points[[i]]$y
  
  # draw plot
  lines(cos(th), sin(th), lty=3)                 # outer circle
  lines(x, y, col=col, pch=19, type="p", cex=3)  # dots
}
par(op) # reset plot parameters
```



## Running R in the cloud

- Service like [Google cloud platform](https://cloud.google.com/sdk/) allow you to spin up vitual machines hat you can access over the web, and they can run things like RStudio server.
- You can use the `googleComputeEngineR` package to set something like that up
- Example:

<img src="./img_misc/gcloudrstudio.png" width=800>

