---
title: "12. Prelude to data"
output:
  html_document:
    includes:
      in_header: header.html    
    toc: true
    toc_float: true
    theme: flatly
    highlight: textmate
    css: mystyle.css
    number_sections: true
    pandoc_args: [
      "--number-offset", 12
    ]
---

```{r,echo=FALSE}
rm(list=objects()) # start with a clean workspace
source("knitr_tweaks.R")
library(lsr,quietly = TRUE)
```

When teaching statistics and data analysis, there is a school of thought that argues that the student should be introduced to actual data as quickly as possible. In one sense I've broken that rule rather substantially. The entirety the *core toolkit* section went by without any real data, much less any data analysis. In my defence, data analysis was never the intended goal of that section. My hope with that section was to teach enough programming concepts that you'd be able to implement a psychological model in R, as we did with the [Rescorla-Wagner model](./programming.html) previously. 

In this section I'm going to shift the focus to data analysis. I won't talk much about statistical inference about data (that will come in a later section) though. Instead we'll cover topics like tidying data, summarising data and visualising data. As the focus is now explicitly on data, I'll now work with real data. 

## Attendance at the football

The data I'll look at first is one that I put together as part of the *Learning Statistics with R* book. It consists of information about every game of Australian Rules Football (AFL) played between 1987 and 2010. The data are available in the [afl.csv](./data/afl.csv) file. Let's load the data set and take a look at it:

```{r, message = FALSE, warning = FALSE, fig.width=7}
library(tidyverse)
afl <- read_csv("./data/afl.csv")
afl
```

For the moment let's not worry too much about what this code is doing or what the output means. The gist of the output is pretty clear. We have information about 4296 games. For each game we have the names of the home and away team, the number of points scored by each team, the date the game was played, the venue where it was played, the official attendance statistics, and whether it was a regular home-and-away game or part of the finals series. 

How do I extract meaningful information out of this data set? Let's say my goal is to investigate how the average attendance at AFL games has changed over the years, and I'd like to look at regular season games separate from finals. To do so, I first summarise the AFL data in terms of the relevant variables: 

```{r, message = FALSE, warning = FALSE, fig.width=7}
attendance <- afl %>% 
  group_by(year, game_type) %>% 
  summarise(attendance = mean(attendance)) 
attendance
```

This summary contains the information I need, but it's a lot easier to understand if I turn it into a pretty picture. Again, I can do that with a short command:

```{r, message = FALSE, warning = FALSE, fig.width=7}
pic <- attendance %>%
  ggplot(aes(x = year, y = attendance)) + 
  facet_wrap(~game_type) +
  geom_point() + 
  geom_smooth() 
plot(pic)
```

It is only at this point the data speak for themselves. Attendance at home and away games (right panel) rose smoothly from 1987 to 2010. For finals games (left panel) the attendance is higher throughout but the trend is different. Average attendance declined somewhat until about 2004 and then rose thereafter. Noting that, a data analyst would be prompted to investigate further. 

My goal in this section is to introduce the R tools that I used in this analysis. So before going into any of the details about data analysis in R, I'll comment on a few things going on in the code I've shown above.

## The tidyverse

The first line of code in the AFL example is `library(tidyverse)`. Per the description on the [tidyverse](https://www.tidyverse.org/) website,

> The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. 

When I wrote *Learning Statistics with R* to accompany my first statistics class the tidyverse didn't play much of a part, because most of it didn't exist. Over the last several years the tidyverse has had a huge influence on how data analysis in R is typically conducted, so in these notes I'll very often rely on tools from the tidyverse. 

## Reading CSV data

In the second line of code I use the `read_csv` function to import the data into R. The command is this one:

```{r, eval=FALSE}
afl <- read_csv("./data/afl.csv")
```

The raw data itself is stored as a *comma separated value* (CSV) file, a plain text file in which each row represents a single game, with values separated by commas. The screenshot below shows the raw data file open in a text editor:

<img src="./img/csv_afl.png" width=800px>

So what this line of code does is import the data from the text file shown in the screen shot, assign it to a variable called `afl`. The format of this AFL variable looks rather like a table, and is an example of an R data formay known as a **tibble**. Later we'll talk more about tibbles, and the closely related **data frame**. For now, let’s just be happy that we imported the data and that it looks about right.

One thing I will mention is that RStudio provides a nice point-and-click method for importing CSV data. Go to the environment pane, select the "import data set" and then choose "from text (readr)", like so^[**readr** is the name of the particular tidyverse package that supplies the `read_csv` function. There is a `read.csv` function that comes with R, but I've come to prefer the tidyverse version.] 


<img src="./img/csv_import1.png" width=300px>

After selecting the file you want to import, RStudio will present you with an import data window that looks like this:

<img src="./img/csv_import2.png" width=800px>

This should look fairly familiar to anyone who has imported data from other software such as Excel or SPSS. I won't use that method in these notes because it's easier to type `read_csv` but it's worth noting that the option is there.


## Pipe operator, `%>%`

**WRITE ME**

```{r,eval = FALSE}
afl %>% 
  group_by(year, game_type) %>% 
  summarise(attendance = mean(attendance)) 
```

The pipe is discussed in some detail in Hadley Wickham's [R for Data Science](http://r4ds.had.co.nz/pipes.html) book.

## Other remarks

Before turning to a discussion of [data types](./data-types.html) there are two other things I want to briefly comment upon in this example. Take a look at the code I used to draw the figure:

```{r,eval = FALSE}
ggplot(aes(x = year, y = attendance)) + 
  facet_wrap(~game_type) +
  geom_point() + 
  geom_smooth() 
```

The format of this command is written as if it were a sum. That is, it takes the form of `ggplot() + facet_wrap() + geom_point() + geom_smooth()`. I'll explain the details when discussing data visualisation but for the moment I want to mention this because it might seem odd. Clearly we aren't doing anything like the addition in the usual sense of the term; in this context `+` means something more akin to "adding a layer to a plot". 

The second odd feature is the part of the code that reads `~ game_types`. The **tilde operator** `~` is used to specifies a kind of R object known as a **formula**. Formulas were originally introduced into R as a convenient way to specify statistical models (especially linear regression models) but they appear a lot of different contexts. Stated simply, a formula object is a variable, but it’s a special type of variable that specifies a relationship between other variables. So in a regression context I might write a "two-sided" formula like this
```{r,eval=FALSE}
outcome ~ predictor1 + predictor2
```
In other contexts I might construct a cross-tabulation with a "one-sided" formula like this
```{r,eval=FALSE}
~ variable1 + variable2
```
Formulas are pretty flexible things, and so different functions will make use of different formats, depending on what the function is intended to do. 




<!--

## Matching cases with `%in%`

Let’s start with a simple example. When my children were little I naturally spent a lot of time watching TV shows like *In the Night Garden*. In the `nightgarden.Rdata` file, I’ve transcribed a short section of the dialogue from the show. The file contains two vectors, `speaker` and `utterance`, and when we take a look at the data,
```{r}
load("./data/nightgarden.Rdata")
print(speaker)
print(utterance)
```


A second useful trick for extracting a subset of a vector is to use the `%in%` operator. It’s actually very similar to the `==` operator, except that you can supply a collection of acceptable values. For instance, suppose I wanted to find those cases when the `utterance` is either `“pip”` or `“oo”`. We can do that like this:

```{r}
utterance %in% c("pip","oo")
```

This in turn allows us to find the `speaker` for all such cases, 

```{r}
speaker[ utterance %in% c("pip","oo") ]
```

-->




<!--

## Generic functions

There’s one other important thing that I omitted when I discussed functions earlier on, and that’s the concept of a **generic function**. The two most notable examples that you’ll see in the next few chapters are `summary` and `plot`, although you’ve already seen an example of one working behind the scenes, and that’s the `print` function. The thing that makes generics different from the other functions is that their behaviour changes, often quite dramatically, depending on the `class` of the input you give it. The easiest way to explain the concept is with an example. With that in mind, lets take a closer look at what the `print` function actually does. I’ll do this by creating a formula, and printing it out in a few different ways. First, let’s stick with what we know:

```{r}
my.formula <- blah ~ blah.blah  # create a variable of class "formula"
print( my.formula )             # print it the normal way
```

So far, there’s nothing very surprising here. But there’s actually a lot going on behind the scenes here. When I type `print(my.formula)`, what actually happens is the `print` function checks the class of the `my.formula` variable. When the function discovers that the variable it’s been given is a formula, it goes looking for a function called `print.formula`, and then delegates the whole business of printing out the variable to the `print.formula` function.^[For readers with a programming background: R has three separate systems for object oriented programming. The earliest system was S3, and it was very informal: generic functions as described here are part of the S3 system. Later on S4 was introduced as a more formal way of doing things. I confess I never learned S4 because it looked tedious. More recently R introduced Reference Classes, which look kind of neat and I should probably learn about them. Discussed [here](http://adv-r.had.co.nz/R5.html) if you're interested.] For what it’s worth, the name for a “dedicated” function like `print.formula` that exists only to be a special case of a generic function like `print` is a **method**, and the name for the process in which the generic function passes off all the hard work onto a method is called **method dispatch**. You won’t need to understand the details at all for this book, but you do need to know the gist of it; if only because a lot of the functions we’ll use are actually generics.

Just to give you a sense of this, let's do something silly and try to bypass the normal workings of the `print` function:

```{r}
print.default( my.formula ) # do something silly by using the wrong method
```

Hm. You can kind of see that it is trying to print out the same formula, but there’s a bunch of ugly low-level details that have also turned up on screen. This is because the `print.default` method doesn’t know anything about formulas, and doesn’t know that it’s supposed to be hiding the obnoxious internal gibberish that R produces sometimes. 

At this stage, this is about as much as we need to know about generic functions and their methods. In fact, you can get through the entire book without learning any more about them than this, so it’s probably a good idea to end this discussion here.

-->

