---
title: "Other Applications"
output:
  html_document:
    includes:
      in_header: header.html    
    toc: true
    toc_float: true
    theme: flatly
    highlight: textmate
    css: mystyle.css
    number_sections: true
    pandoc_args: [
      "--number-offset", 99
    ]
---

```{r,echo=FALSE}
rm(list=objects()) # start with a clean workspace
source("knitr_tweaks.R")
```


>The garden of life never seems to confine itself to the plots philosophers have laid out for its convenience. Maybe a few more tractors would do the trick.<br>
> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;â€“ Roger Zelazny, *Home is the Hangman*, 1975
 
It's a big world out there, and there are a lot of people doing really interesting thing with R (and other tools too of course). You can get a sense of what the possibilities are by looking online (e.g., awesome-r.com has a list of very neat packages). This chapter briefly discusses a few possibilities, most of which I chose on a whim!

## Coding text based tasks

Sometimes it's just too much effort to set up a whole Shiny app. Maybe all you want to do is have some simple text based interaction, and you'd be perfectly happy to go old school and have the user respond in the R console. Here's a simple example:

```{r, eval=FALSE}
# An interactive game at the console

# A sneaky trick: RStudio recognises the "form feed" character
# as a cue to clear all the text in the console. If we send it
# to the console using "cat" it functions as a way of clearing
# the screen. Define a "clearscreen" function...
clearscreen <- function(){
  cat("\f") # form feed character: "\014"
}

# clear the screen
clearscreen()

# initialise the data as an empty data frame 
dataset <- data.frame(
  trial = numeric(0),
  upper = numeric(0),
  lower = numeric(0),
  query = numeric(0),
  response = character(0)
)

# initialise the state of the experiment
low <- 1   # lowest possible number
up <- 100  # highest possible number
rng <- up-low # possible uncertainty?
trial <- 1

# keep guessing until the answer is known
while( rng > 1 ) {
  
  # sample a query item
  que <- sample(low:up,1)
  
  # ask the question until the user responds with "y" or "n"
  cat("\n\n\n\n\n")
  resp <- ""
  while( !(resp %in% c("y","n"))) {
    prompt <- paste0("Is it higher than ", que, "? [y/n]  ")
    resp <- readline(prompt)
    resp <- tolower(resp)
  }
  
  # record the data
  dataset <- rbind(
    dataset, 
    data.frame(
      trial=trial,
      upper=up,
      lower=low,
      query=que,
      response=resp
    )
  )

  # use the user response to update the bounds
  if(resp == "y") {
    low <- que
  } else{ 
    up <- que
  }
  
  # update the rest of the state accordingly
  rng <- up-low
  trial <- trial + 1
  
  # clear the screen in readiness for the next trial
  clearscreen()
  
}

# end the experiment
cat("Done!\n\n")
print(dataset)
```



## Twitter client

Researchers interested in social networks often scrape data from sites such as Twitter in order to obtain data. This is relatively easy to do in R, using a package like `twitteR`, which provides an interface with the Twitter web API. 

### Setting up `twitteR`

It's fairly easy to get set up (e.g. [this post](https://www.r-bloggers.com/setting-up-the-twitter-r-package-for-text-analytics/)): 

1. Install the `twitteR` package
2. Get a twitter account 
     - I have @lsrbook for this
     - you do need to add a mobile number (for Australian numbers, drop the leading 0)
3. Go to https://apps.twitter.com (sign in with your account)
4. Click on "create new app"
5. Enter the information it requests: you need a name, a description, a website. For my client I set
     - lsr-book-twitter-app
     - R twitter client for teaching purposes
     - I used https://learningstatisticswithr.com (the post suggests: https://bigcomputing.blogspot.com)
6. Agree to terms and conditions

At this point the app is created on the Twitter side. You'll need to get some information to allow R access to the app:

7. Click on "key & access token" tab and get the following:
      - Consumer Key (API Key)
      - Consumer Secret (API Secret)
8. Go to the "create my access token" button:
      - Access Token
      - Access Token Secret

This is all R needs so go back to R and enter the following:

```{r,eval=FALSE}
consumer_key <- "XXXXX"
consumer_secret <- "XXXXX"
access_token <- "XXXXX"
access_secret <- "XXXXX"
```

where the `"XXXXX"` values are of course the keys you just downloaded. Within R the command to authorise the `twitteR` package access to the app is:

```
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
```
Now we're ready to go!

### Using the Twitter client

Okay, so I guess people like to tweet about `#thedrum` so I decided to search for the last 10000 tweets containing that term. It's easy to do:

```{r, eval=FALSE}
library(twitteR)

drumtweet10k <- searchTwitter(
  searchString = "thedrum", 
  n=10000
)
```

```{r,echo=FALSE,eval=FALSE}
load("dt10k.Rdata")

dt10k_txt <- sapply(drumtweet10k, function(x){x$text})
dt10k_bow <- unlist(strsplit(dt10k_txt, " "))

dt10k_stp <- dt10k_bow
dt10k_stp <- gsub("&amp;","&",dt10k_stp,fixed=TRUE)
stopchars <- strsplit("[\\:!$%&()*+,-./;<=>'[]^_]","")[[1]]
for(s in stopchars) {
  dt10k_stp <- gsub(s,"",dt10k_stp,fixed=TRUE)
}
dt10k_stp <- gsub(" ","",dt10k_stp,fixed=TRUE)
dt10k_stp <- iconv(dt10k_stp, "latin1", "ASCII", sub="")
dt10k_stp <- tolower(dt10k_stp)

stopwords <- as.character(unlist(read.csv("./stop-word-list.csv",header=FALSE)))
stopwords <- gsub(" ","",stopwords,fixed=TRUE)
stopwords <- c(stopwords," ")

boring <- dt10k_stp %in% stopwords
dt10k_stp <- dt10k_stp[!boring]
dt10k_stp <- dt10k_stp[nchar(dt10k_stp)>0]

freq <- table(dt10k_stp)
freq <- sort(freq,decreasing = TRUE)[1:100]

save(freq,dt10k_stp,dt10k_txt,stopchars,stopwords,file="./data/dt10k-sml.Rdata")
```

The raw data are saved in the `dt10k.Rdata`. The format of the data is a little complicated, so I did a tiny bit of text processing and tidying, and then saved the results to `dt10k-sml.Rdata`. Let's take a look:

```{r}
load("./data/dt10k-sml.Rdata")
library(lsr)
who()
```

In the full data set the twitter client has downloaded a lot of information about each tweet, but in this simpler versionm `dt10k_txt` variable contains only the raw text of each tweet. Here's the first few tweets:
```{r}
dt10k_txt[1:5]
```

The `dt10k_stp` vector concatenates all the tweets, splits them so that each word is a separate element, after removing punctuation characters, converting everthing to lower case, and removing certain `stopwords` that are very high frequency but rarely interesting:

```{r}
dt10k_stp[1:50]
```

The `freq` variable is a frequency table for the words in `dt10k_stp`, sorted in order of decreasing frequency. Here are the top 20 words:

```{r}
names(freq[1:20])
```

Just to illustrate that there is psychological value in this approach, here's the standard "rank-frequency plot", showing the signature (approximately) power-law behaviour. There are a few *extremely* common words, and then a *very* long tail of low frequency words. Variations on this pattern are ubiquitous in natural language:  

```{r,fig.width=7}
plot(
  x = freq[1:100], 
  xlab="Word", 
  ylab="Frequency"
)
```

That said, I do wonder how much of this data set is spam. There seem to be a lot of tweets about blockchain in there, which does make me suspicious. I may have to revisit this example in the future!


## Animated plots

- You need [ffmpeg](http://ffmpeg.org/) installed first (this can be tedious)
- The `animate` package does the work in R: an animation is just a sequence of plots that can be written to a variety of different animation formats 
- Example:

```{r,fig.show="animate", interval=0.1, aniopts="controls", fig.width=5, fig.height=5,cache=TRUE,echo=FALSE,eval=FALSE}
# [DO NOT RUN - cached link below]

n <- 100           # number of points
col <- rainbow(n)  # all the colours of the rainbow
s <- .02           # how much noise in the diffusion
ntime <- 200       # how many time points

# drift
phi <- seq(0,pi,length.out = n) # angle of the drift
nu <- .015                      # rate of the drift
dx <- nu * cos(phi)  # x-component of drift
dy <- nu * sin(phi)  # y-component of drift

# start
x <- y <- rep.int(0,n)    # all points at the origin
moving <- rep.int(TRUE,n) # all points moving

# storage
points <- list()
points[[1]] <- list(x=x,y=y)

# iterate over time
for(i in 2:ntime){
  nm <- sum(moving) # how many points are moving 
  
  x[moving] <- x[moving] + dx[moving] + rnorm(nm)*s # move x co-ord
  y[moving] <- y[moving] + dy[moving] + rnorm(nm)*s # move y co-ord
  
  l <- x^2 + y^2            # have we hit boundary
  moving[l >= 1] <- FALSE   # freeze points when we do
  
  points[[i]] <- list(x=x,y=y) # storage
}

op <- par(no.readonly = TRUE) # plot set up
par(mar=c(1,1,1,1))           # plot margins
th <- seq(0,2*pi,.01)         # points for outer circle

for(i in seq(ntime,1,-1)) { # go backwards in time to be pretty!
  
  # initialise plot
  plot.new()
  plot.window(
    xlim=c(-1.1,1.1),
    ylim=c(-1.1,1.1)
  )
  
  # read the current locations
  x <- points[[i]]$x
  y <- points[[i]]$y
  
  # draw plot
  lines(cos(th), sin(th), lty=3)                 # outer circle
  lines(x, y, col=col, pch=19, type="p", cex=3)  # dots
}
par(op) # reset plot parameters
```
<video width="480"  controls>
<source src="misc_dotsanimate/figure-html/unnamed-chunk-11.webm" />
</video>

## Using `rgl` for OpenGL and WebGL

The `rgl` package provides a method for constructing interactive 3D plots, using the OpenGL graphics engine. Conveniently it also allows you make use of the WebGL engine, which means that you can insert your fancy 3D graphics into a web page. On a Mac, you'll need to make sure you have [XQuartz](https://www.xquartz.org/) installed and running on your machine. Here's a simple example, shamelessly lifted straight from the `rgl` documentation... 

```{r}
library(rgl)
with(iris, plot3d(Sepal.Length, Sepal.Width, Petal.Length, 
                  type="s", col=as.numeric(Species)))
rglwidget(elementId = "plot3drgl")
```

If you click and drag on the image you can rotate it as much as you like. Better yet, because OpenGL and WebGL are genuine 3D graphics engines, you can manipulate the scene and control things like lighting, material and so on. I confess this isn't an area I know at all well, but I suspect it would be handy for some research projects. 

Another example, slightly adapted from the package documentation:

```{r}
data(volcano) # load the volcano data set

zval <- 5 * volcano        # increase the height
xval <- 15 * (1:nrow(zval))   # spacing (S to N)
yval <- 15 * (1:ncol(zval))   # spacing (E to W)

zlim <- range(yval)
zlen <- zlim[2] - zlim[1] + 1
colorlut <- terrain.colors(zlen)   # height color lookup table
col <- colorlut[ zval - zlim[1] + 1 ] # assign colors to heights for each point

# create a new rgl device, but don't display it
open3d(useNULL = TRUE)

# draw the surface
surface3d(
  x = xval,
  y = yval,
  z = zval,
  color = col,
  ambient = "grey10",
  shininess = 75,
  back = "lines"
)

# write scene to widget
s <- scene3d()
rglwidget(s)
```



## Running R in the cloud

- Service like [Google cloud platform](https://cloud.google.com/sdk/) allow you to spin up vitual machines that you can access over the web, and they can run things like RStudio server.
- You can use the `googleComputeEngineR` package to set something like that up
- Example:

<img src="./img_misc/gcloudrstudio.png" width=800>

