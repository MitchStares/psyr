<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Probability Distributions</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<!-- ###### start inserted header ##### -->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-115940772-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-115940772-1');
</script>

<!-- add the twitter card and open graph tags -->
<meta name="twitter:card" content="summary">
<meta name="twitter:creator" content="@djnavarro">
<meta property="og:url" content="http://compcogscisydney.org/psyr/">
<meta property="og:title" content="R for Psychological Science">
<meta property="og:description" content="An introductory resource">
<meta property="og:image" content="http://compcogscisydney.org/psyr/img/splash_turtle.png">

<!-- ###### end inserted header ##### -->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="mystyle.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}

.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">R for Psychological Science</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Core
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="getting-started.html">Getting started</a>
    </li>
    <li>
      <a href="variables.html">Variables</a>
    </li>
    <li>
      <a href="scripts.html">Scripts</a>
    </li>
    <li>
      <a href="packages.html">Packages</a>
    </li>
    <li>
      <a href="workspaces.html">Workspaces</a>
    </li>
    <li>
      <a href="vectors.html">Vectors</a>
    </li>
    <li>
      <a href="loops.html">Loops</a>
    </li>
    <li>
      <a href="branches.html">Branches</a>
    </li>
    <li>
      <a href="functions.html">Functions</a>
    </li>
    <li>
      <a href="programming.html">Programming</a>
    </li>
    <li>
      <a href="file-system.html">File system</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="prelude-to-data.html">Prelude</a>
    </li>
    <li>
      <a href="data-types.html">Data types</a>
    </li>
    <li>
      <a href="describing-data.html">Describing data</a>
    </li>
    <li>
      <a href="visualising-data.html">Visualising data</a>
    </li>
    <li>
      <a href="manipulating-data.html">Manipulating data</a>
    </li>
    <li>
      <a href="working-with-text.html">Text data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Stats
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="xx-distributions.html">Probability distributions</a>
    </li>
    <li>
      <a href="xx-introductory-statistics.html">Introductory statistics</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    More
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="xx-shiny.html">Shiny apps</a>
    </li>
    <li>
      <a href="xx-miscellaneous.html">Miscellaneous</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://compcogscisydney.org">compcogscisydney.org</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Probability Distributions</h1>

</div>


<div id="prelude" class="section level2">
<h2><span class="header-section-number">99.1</span> Prelude</h2>
<p>R is very often described as a <em>statistical programming environment</em>, because - while it does get used for an incredible variety of purposes - it began its life as a tool for helping statisticians analyse data. As such, it has an unrivalled collection of statistical packages built into it, and I’ll talk a little about some of them later. However, before starting to talk about statistics, it’s very useful to talk about <em>probability distributions</em> and how they are usually implemented in R.</p>
<p>Speaking of which, what exactly is the difference between probability theory and statistics? The two disciplines are closely related but they’re not identical. Probability theory is “the doctrine of chances”. It’s a branch of mathematics that tells you how often different kinds of events will happen. For example, all of these questions are things you can answer using probability theory:</p>
<ul>
<li>What are the chances of a fair coin coming up heads 10 times in a row?</li>
<li>If I roll two six sided dice, how likely is it that I’ll roll two sixes?</li>
<li>How likely is it that five cards drawn from a perfectly shuffled deck will all be hearts?</li>
<li>What are the chances that I’ll win the lottery?</li>
</ul>
<p>Notice that all of these questions have something in common. In each case the “truth of the world” is known, and my question relates to the “what kind of events” will happen. In the first question I <em>know</em> that the coin is fair, so there’s a 50% chance that any individual coin flip will come up heads. In the second question, I <em>know</em> that the chance of rolling a 6 on a single die is 1 in 6. In the third question I <em>know</em> that the deck is shuffled properly. And in the fourth question, I <em>know</em> that the lottery follows specific rules. You get the idea. The critical point is that probabilistic questions start with a known <strong>model</strong> of the world, and we use that model to do some calculations. The underlying model can be quite simple. For instance, in the coin flipping example, we can write down the model like this: <span class="math display">\[
P(\mbox{heads}) = 0.5
\]</span> which you can read as “the probability of heads is 0.5”. As we’ll see later, in the same way that percentages are numbers that range from 0% to 100%, probabilities are just numbers that range from 0 to 1. When using this probability model to answer the first question, I don’t actually know exactly what’s going to happen. Maybe I’ll get 10 heads, like the question says. But maybe I’ll get three heads. That’s the key thing: in probability theory, <em>the model is known, but the data are not.</em></p>
<p>So that’s probability. What about statistics? Statistical questions work the other way around. In statistics, we do not know the truth about the world. All we have is the data, and it is from the data that we want to learn the truth about the world. Statistical questions tend to look more like these:</p>
<ul>
<li>If my friend flips a coin 10 times and gets 10 heads, are they playing a trick on me?</li>
<li>If five cards off the top of the deck are all hearts, how likely is it that the deck was shuffled?</li>
<li>If the lottery commissioner’s spouse wins the lottery, how likely is it that the lottery was rigged?</li>
</ul>
<p>This time around, <em>the only thing we have are data</em>. What I know is that I saw my friend flip the coin 10 times and it came up heads every time. And what I want to <strong>infer</strong> is whether or not I should conclude that what I just saw was actually a fair coin being flipped 10 times in a row, or whether I should suspect that my friend is playing a trick on me. The data I have look like this: <span class="math display">\[
HHHHHHHHHHH
\]</span> and what I’m trying to do is work out which “model of the world” I should put my trust in. If the coin is fair, then the model I should adopt is one that says that the probability of heads is 0.5; that is, <span class="math inline">\(P(\mbox{heads} = 0.5\)</span>. If the coin is not fair, then I should conclude that the probability of heads is not 0.5, which we would write as <span class="math inline">\(P(\mbox{heads} \neq 0.5\)</span>. In other words, the statistical inference problem is to figure out which of these probability models is right. Clearly, the statistical question isn’t the same as the probability question, but they’re deeply connected to one another. Because of this, a good introduction to statistical theory will start with a discussion of what probability is and how it works.</p>
<div id="what-does-probability-mean" class="section level3">
<h3><span class="header-section-number">99.1.1</span> What does probability mean?</h3>
<p>Let’s start with the first of these questions. What is “probability”? It might seem surprising to you, but while statisticians and mathematicians (mostly) agree on what the rules of probability are, there’s much less of a consensus on what the word really means. It seems weird because we’re all very comfortable using words like “chance”, “likely”, “possible” and “probable”, and it doesn’t seem like it should be a very difficult question to answer. If you had to explain “probability” to a five year old, you could do a pretty good job. But if you’ve ever had that experience in real life, you might walk away from the conversation feeling like you didn’t quite get it right, and that (like many everyday concepts) it turns out that you don’t really know what it’s all about. In the statistic literature there are two qualitatively different ideas about how to define the term:</p>
<ul>
<li>The <strong>frequentist view </strong> defines probability as <em>long-run frequency</em>. Suppose we were to try flipping a fair coin, over and over again, and divide the number of heads <span class="math inline">\(n_h\)</span> by the total number of coin flips <span class="math inline">\(n\)</span>, yielding <span class="math inline">\(p_h = n_h/n\)</span> as the observed proportion. The frequentists argue that the only way to meaningfully define the idea of probability is in terms of what happens to this empirically observed proportion a the sample size becomes arbitrarily large (i.e., <span class="math inline">\(n \rightarrow \infty\)</span>). In the long run, the proportion of heads will eventually converge to 50%. There are some subtle technicalities that the mathematicians care about, but qualitatively speaking, that’s how the frequentists define probability. Probability is a “thing in the world”</li>
<li>The <strong>Bayesian view</strong> is often called the subjectivist view, and it is a minority view among statisticians, but one that has been steadily gaining traction for the last several decades. There are many flavours of Bayesianism, making hard to say exactly what “the” Bayesian view is. The most common way of thinking about subjective probability is to define the probability of an event as the <em>degree of belief</em> that an intelligent and rational agent assigns to that truth of that event. From that perspective, probabilities don’t exist in the world, but rather in the thoughts and assumptions of people and other intelligent beings. However, in order for this approach to work, we need some way of operationalising “degree of belief”. One way that you can do this is to formalise it in terms of “rational gambling”, though there are many other ways. Suppose that I believe that there’s a 60% probability of rain tomorrow. If someone offers me a bet: if it rains tomorrow, then I win $5, but if it doesn’t rain then I lose $5. Clearly, from my perspective, this is a pretty good bet. On the other hand, if I think that the probability of rain is only 40%, then it’s a bad bet to take. Thus, we can operationalise the notion of a “subjective probability” in terms of what bets I’m willing to accept. Probability, from this perspective, is a “thing in the head”.</li>
</ul>
<p>My personal view is much closer to the Bayesian perspective, and I tend to use Bayesian methods myself, but I’ll talk a bit about both approaches in this book. Regardless of which version you prefer, the core <em>mechanics</em> for working with probabilities in R are the same.</p>
</div>
<div id="quick-reference" class="section level3">
<h3><span class="header-section-number">99.1.2</span> Quick reference</h3>
<p>The tools for working with probability distributions in R tend to be fairly standardised. If I want to work with a normal distribution, for instance, there are four different functions - <code>rnorm</code>, <code>dnorm</code>, <code>pnorm</code> and <code>qnorm</code>. If I want to work with a uniform distribution, the functions are named <code>runif</code>, <code>dunif</code>, <code>punif</code> and <code>qunif</code>. For a binomial distribution, they are <code>rbinom</code>, <code>dbinom</code>, <code>pbinom</code> and <code>qbinom</code>. The four versions are:</p>
<ul>
<li>The <strong>r form</strong> is a random number generator: you can use it to sample <code>n</code> random outcomes from the distribution.</li>
<li>The <strong>d form</strong> computes the probability (or probability density) with which you would observe a particular number <code>x</code> if it is generated from this distribution.</li>
<li>The <strong>p form</strong> is the cumulative distribution function. You specify a particular value <code>q</code>, and it tells you the probability of obtaining an outcome smaller than or equal to <code>q</code>.</li>
<li>The <strong>q form</strong> calculates the quantiles of the distribution. You specify a probability value <code>p</code>, and gives you the corresponding percentile. That is, the value of the variable for which there’s a probability <code>p</code> of obtaining an outcome lower than <code>q</code>.</li>
</ul>
</div>
</div>
<div id="the-normal-distribution" class="section level2">
<h2><span class="header-section-number">99.2</span> The normal distribution</h2>
<p>The normal distribution is the most widely used distribution in statistics, so it’s a natural place to start. For example, IQ scores are roughly normally distributed, and the tests are (supposedly) normed in such a way that the average IQ score is 100 and the standard deviation is 15. So let’s use R to randomly generate a sample of <code>n = 50</code> IQ scores using the <code>rnorm</code> function.</p>
<pre class="r"><code>iq &lt;- rnorm(n = 50, mean = 100, sd = 15)  # sample the IQ scores
hist(iq, xlab=&quot;IQ&quot;,main=&quot;&quot;)               # draw the histogram</code></pre>
<p><img src="xx-distributions_files/figure-html/unnamed-chunk-2-1.png" width="456" style="display: block; margin: auto;" /></p>
<p>You can <em>kind of</em> see the shape of the bell curve with 50 observations, but it’s not super obvious. If we ratchet up the sample size to <code>n = 10000</code> data points, it becomes a lot more obvious</p>
<pre class="r"><code>iq &lt;- rnorm(n = 10000, mean = 100, sd = 15)  # sample the IQ scores
hist(iq, xlab=&quot;IQ&quot;,main=&quot;&quot;)               # draw the histogram</code></pre>
<p><img src="xx-distributions_files/figure-html/unnamed-chunk-3-1.png" width="456" style="display: block; margin: auto;" /></p>
<p>We can draw the bell curve itself by using the <code>dnorm</code> function:</p>
<pre class="r"><code>iq &lt;- 40:160
prob &lt;- dnorm(x = iq, mean = 100, sd = 15)
plot(iq, prob, xlab=&quot;IQ&quot;,ylab=&quot;Density&quot;, main=&quot;&quot;, type=&quot;l&quot;)</code></pre>
<p><img src="xx-distributions_files/figure-html/unnamed-chunk-4-1.png" width="456" style="display: block; margin: auto;" /></p>
<p>The cumulative distribution function looks like this:</p>
<pre class="r"><code>iq &lt;- 40:160
cprob &lt;- pnorm(q = iq, mean = 100, sd = 15)
plot(iq, cprob, xlab=&quot;IQ&quot;,ylab=&quot;Cumulative Probability&quot;, main=&quot;&quot;, type=&quot;l&quot;)</code></pre>
<p><img src="xx-distributions_files/figure-html/unnamed-chunk-5-1.png" width="456" style="display: block; margin: auto;" /></p>
<p>The quantile function is just the inverse of the cumulative distribution (i.e., x and y axes are swapped):</p>
<pre class="r"><code>prob &lt;- seq(from = .01, to = .99, by = .01)
q &lt;- qnorm(p = prob, mean = 100, sd = 15)
plot(prob, q, xlab=&quot;Probability&quot;,ylab=&quot;Quantile&quot;, main=&quot;&quot;, type=&quot;l&quot;)</code></pre>
<p><img src="xx-distributions_files/figure-html/unnamed-chunk-6-1.png" width="456" style="display: block; margin: auto;" /></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
