---
title: "16. Manipulating data"
output:
  html_document:
    includes:
      in_header: header.html    
    toc: true
    toc_float: true
    theme: flatly
    highlight: textmate
    css: mystyle.css
    number_sections: true
    pandoc_args: [
      "--number-offset", 16
    ]
---

```{r,echo=FALSE,message = FALSE, warning = FALSE}
rm(list=objects()) # start with a clean workspace
source("knitr_tweaks.R")
library(tidyverse,quietly = TRUE)
```

```{css,echo=FALSE}
h1{
  line-height: 100px;
}
h2{
  line-height: 80px;
}
h3{
  line-height: 60px;
}
```

Data manipulation isn't a particularly well defined topic. I take it to cover a few topics:

- Importing and exporting data
- Cleaning up errors in data
- Reorganising data

Earlier sections of the notes covered variations of this:

- Reading and writing from CSV files and .RData files
- Creating data frames, tibbles and factors from other input
- Using filter and select to extract subsets of a data frame
- Using mutate to create or alter columns in a data frame
- Using arrange to sort a data frame

## An illustrative problem

In the [data visualisation](./visualising-data.html) we used a data set looking at inductive reasoning stored in the [frames_ex2.csv](./data/frames_ex2.csv) file. Here it is again:

```{r, message=FALSE}
frames <- read_csv("./data/frames_ex2.csv")
frames
```

In this file the data are stored in *long form*, in which there is one row for every trial in the experiment and thus the data from each participant are spread across several rows. I stored the data in that format because it was handy for drawing pictures, but as it happen this isn't how the data set was stored when I extracted it from the [OSF repository](https://osf.io/j4dxm/) in which I'd deposited it only a few months earlier! Here's what it looked like when I found it:

```{r, message=FALSE}
wide_frames <- read_csv("./data/frames_ex2_wide.csv")
wide_frames
```

In this file, the data are stored in *wide form*. The data frame contains only one row per person, and each judgment they make is stored as a separate variable. Wide and long form data are useful for a number of purposes. How do we switch between them, "reshaping" the data to the form we need? 

Once upon a time this used to be a difficult task, so much so that I wrote my own (not very good) functions that would solve this problem in a way that didn't expose my students to some of the more frustrating aspects of data manipulation. Thankfully, this has changed. There is a little package distributed with the tidyverse called **tidyr** and it is remarkably effective at solving a range of reshaping problems in a (fairly) intuitive way. 

## Reshaping a data frame

```{r}
long_frames <- wide_frames %>% 
  gather(key = "query", value="response",
         "SS2-R1", "SS2-R2","SS2-R3","SS2-R4","SS2-R5","SS2-R6","SS2-R7",
         "SS6-R1","SS6-R2","SS6-R3","SS6-R4","SS6-R5","SS6-R6","SS6-R7", 
         "SS12-R1","SS12-R2","SS12-R3","SS12-R4","SS12-R5","SS12-R6","SS12-R7")
long_frames
```

To go back the other way, we could do this:

```{r}
long_frames %>% spread(key = "query", value = "response")
```


## Splitting a variable

The `long_frames` data frame we created is close to what we need, but the `query` variable isn't quite right. A value of `"SS2-R1"` corresponds to a trial on which the sample size was 2 and the test item was 1. This should properly be two variables, one specifying the `sample_size` and the other specifying the value of the `test_item`. 

```{r}
long_frames %>% 
  separate(
    col = query, 
    into = c("sample_size","test_item"), 
    sep = "-R"
  )
```

Getting closer. Note that there is a `unite()` function that reverses this operation, so if you ever need to collapse multiple columns into a single variable that would be the way to do it. It's also worth noting that the two new variables aren't quite in the format we want them to be. For instance, the `test_item` variable should be numeric rather than character, so lets `mutate` that and store the results:

```{r}
long_frames <- long_frames %>% 
  separate(
    col = query, 
    into = c("sample_size","test_item"), 
    sep = "-R"
  ) %>%
  mutate(test_item = as.numeric(test_item))
long_frames
```

## Recoding variables

### Using `recode()`

What should we do with the `sample_size` variable?

```{r}
long_frames <- long_frames %>%
  mutate(sample_size = dplyr::recode(
    sample_size, 
    "SS2" = "small", 
    "SS6" = "medium", 
    "SS12" = "large")
  )
long_frames
```

### Using `case_when()`

An alternative method is to use `case_when()`. 

```{r}
long_frames <- long_frames %>%
  mutate(n_obs = case_when(
    sample_size == "small" ~ 2,
    sample_size == "medium" ~ 6,
    sample_size == "large" ~ 12
  ))
long_frames
```

Now we have a data frame that is almost identical to the one we imported in the previous section. Apart from some cosmetic changes to variable names and order, the job is complete!

## Processing dates

Empirical data sets often include date fields. Sometimes these dates are nicely formatted and are easy to work with. Most of the time they are not. Even if they were, dates are inherently painful: a year isn't a perfect multiple of days, so a solar calendar needs leap years and other corrections. The year doesn't divide easily into 12 months so months have a variable number of days and doing "addition" with months is really weird. The week days don't distribute themelves cleanly across months or years, so those are a headache too `r emo::ji("face_with_head_bandage")`. It's not purely an issue of nomenclature. We organise our lives around seasons, weekdays/weekends, day/night and various other cycles that don't always play nicely with one another. The weirdness of dates reflects the structure of the world and our lives, and data analysts can't pretend that this complexity isn't there. To make things more annoying there are cultural and lingustic variations even within the English speaking world, so that is an additional source of ambiguity. Does 9/11 refer to September 11 or November 9? It depends on where you live. `r emo::ji("shrug")`. Because of all this, date specification is hard. The `Date` class in R provides a relatively decent way to handle this kind of data, and the **lubridate** package (another tidyverse one!) provides a very helpful tool to make it easier. It doesn't load automatically so lets do that now:

```{r,warning=FALSE,message=FALSE}
library(lubridate)
```

### Getting started

Date information is often specified in terms of "year", "month" and "day", though not always in that order. **lubridate** provides a collection of functions `ymd`, `mdy`, etc that are fairly smart and able to parse information in many different formats. As long as you know the order of the information, these functions work really well: 

```{r, results="hold"}
ymd(20101215)
ymd("2010/12/15")
ymd("2010 December 15")
```

Despite the variations in formatting the function is able to work out that these all correspond to the same date and returns an variable of class `Date`. This gives you quite a bit of flexibility:

```{r}
ymd(20101215) == mdy("12/15/10")
```
Nice! The functions are smart enough to handle strings and numbers as input, and if the year is indeterminate it assumes a 21st century date. That said, they do rely on you knowing the correct order. The same numeric input, formatted differently...

```{r}
dmy(20101215)
```

... might indeed correspond to 20th October 1215. This might be plausible if the data set somehow pertained to the Magna Carta, but probably not for most settings of interest to psychologists!

### A real world example

To give you a sense of how annoying working with dates can be, the following is a real example. I asked my partner -- who in real life is a statistics consultant among other things -- to send me a data set she'd been sent with poorly formatted date information. This is what she sent me:

```{r}
oddball <- readLines("./data/oddballdate2.csv")
oddball
```

To keep this example minimal, I've used `readLines()` to import the data as a single character vector. As you can see this pretty inconsistent, and my partner's face when I turned to her in horror can only be described with emoji: `r emo::ji("smiling_imp")` 

A brief look at this suggests that *most* of the data have a time stamp as well as date information, which suggests that the `dmy_hm` function should be able to parse them. Others are date only, suggesting that `dmy` should work. If I try these individually this is what happens: 

```{r}
dmy(oddball)
dmy_hm(oddball)
```

Each function converts the dates it can, inserts `NA` for the dates it can't, and loudly complain that something is amiss. That's pretty reasonable. 

```{r, warning=FALSE}
d1 <- oddball %>% dmy_hm() %>% date()
d2 <- oddball %>% dmy() 
clean_dates <- case_when(
  is.na(d1) ~ d2, 
  TRUE ~ d1
  )
clean_dates
```

Well that *almost* worked. What's the one `NA` value?

```{r}
oddball[is.na(clean_dates)]
```

Sigh. Looking at all the other dates, every single one is in April or May... but this last one is ostensibly on the 5th day of the 13th month? Obviously we have *one* entry formatted in a `mdy()` form. I will leave it as an exercise to the reader to work out how to fix that one `r emo::ji("grinning")`

## Combining data frames

Another common data manipulation problem arises when we need to combine multiple data frames. Two versions of this problem are worth talking about, namely *binding* and *joining*

### Binding

Binding data frames is simple. Suppose we have multiple data frames that have the same variables, and we want to concatenate them. For instance, here are three small data frames:

```{r,message=FALSE}
nightgarden_top <- read_csv("./data/nightgarden_top.csv")
nightgarden_middle <- read_csv("./data/nightgarden_middle.csv")
nightgarden_bottom <- read_csv("./data/nightgarden_bottom.csv")
```

Each of these contains a subset of the rows we need:

```{r}
nightgarden_middle
```

We can use `dplyr::bind_rows()` to concatenate these data frames vertically:

```{r}
bind_rows(nightgarden_top, nightgarden_middle, nightgarden_bottom)
```

There is an analogous function `dplyr::bind_columns()` that concatenates horizontally.


### Joining

More complicated situations arise when each data frame potentially contains information about the same cases and variables, but not necessarily all the same ones. A common situation in which this arises in real research is when participants complete two different tasks (e.g. a questionnaire and an experimental task) and the data are stored separately from each tasks. Ideally we might hope to have data from every participant for do both versions, but that does not always occur. As a toy example, suppose we collected some `demographics` for major characters from Terry Pratchett's *Discworld* novels:

```{r,message=FALSE}
demographics <- read_csv("./data/discworld_demographics.csv")
demographics
```

Only some of the characters completed this questionnaire however. We might also have obtained `responses` from Discworld characters to some experimental task, and again we have partial data:

```{r,message=FALSE}
responses <- read_csv("./data/discworld_responses.csv")
responses
```

How should we *join* these two data frames together? In general there is no right or wrong answer to this question, merely different possibilities that will be of use in different situations:

- An inner join contains only those rows that appear in both data frames
- A full join contains every row that appears in at least one data frame
- A left join contains every row that appears in the first data frame
- A right join contains every row that appears in the second data frame

In order to work out which rows are matched in the different data frames, the default is to use any variable name that appears in both data sets (though this can be customised). For the *Discworld* data, the only two characters that appear in both the `demographics` data set and the `reponses` data are Vimes and Granny, so when we construct an inner join, we end up with a data frame that includes only those two characters:

```{r}
inner_join(demographics, responses)
```

By contrast, if we construct a full join, every character is included in the result, with `NA` values inserted for all the missing cases:

```{r}
full_join(demographics, responses)
```

Suppose we want to retain data only for those characters that completed the `demographics` survey. A left join is what we need here:

```{r}
left_join(demographics, responses)
```

By analogy, if we wanted to retain data only for those characters that provided `responses`, we would use the `right_join()` function. It's also worth noting that there also `semi_join()` and `anti_join()` functions that can handle other kinds of situations, but I won't go into those here.

## More resources

- For a discussion of [dates using lubridate](https://data.library.virginia.edu/working-with-dates-and-time-in-r-using-the-lubridate-package/) 
